# AXIOM Voice Agent - Terminal Demo Log

This is a cleaned excerpt from an actual terminal session showing AXIOM's voice interaction capabilities.

## System Startup

```
$ ./venv/bin/python3 backend/main_agent_web.py

‚úì Found sherpa-onnx-nemo-parakeet-tdt-0.6b-v3-int8 in models directory
‚úì Found kokoro-en-v0_19 in models directory

01:37:23 [INFO] ================================================================================
01:37:23 [INFO] üöÄ AXIOM WEB AGENT - Initializing with Semantic RAG
01:37:23 [INFO] ================================================================================

01:37:26 [INFO] ‚úÖ STT handler initialized
01:37:26 [INFO] ‚úÖ Intent classifier initialized with 9 intent labels
01:37:27 [INFO] ‚úÖ TTS handler initialized
01:37:27 [INFO] [VAD] Loaded Silero VAD model
01:37:27 [INFO] [KeywordMapper] Loaded 27 products
01:37:27 [INFO] [KeywordMapper] Mapped 136 unique keywords
01:37:27 [INFO] [3D Mapper] Initialized with 4 topic mappings
‚úÖ Using Ollama model: drobotics_test
01:37:27 [INFO] Loaded 325 project ideas

01:37:34 [INFO] Built 27 equipment vectors
01:37:34 [INFO] Built 325 project vectors
01:37:34 [INFO] Built 10 authority vectors
01:37:34 [INFO] ‚úÖ Semantic RAG ready: 27 equipment, 325 projects, 10 authorities

01:37:34 [INFO] ‚úÖ All modules initialized (llama-cpp-python loaded)
01:37:34 [INFO] ‚úÖ Template handler: 2,116 instant responses

INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

## Voice Interaction Examples

### Example 1: Simple Acknowledgment (Template Bypass)
```
01:37:46 [INFO] üîå Client Connected
01:37:47 [INFO] [VAD] üé§ Speech START detected
01:37:48 [INFO] [VAD] üîá Speech END detected - LOCKING audio input

01:37:48 [INFO] üß† PROCESSING SPEECH SEGMENT
01:37:48 [INFO] [Audio Buffer] Collected 13312 samples (0.83s)
01:37:48 [INFO] [üìù Parakeet STT] Raw: "Yeah."

Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 55.34it/s]

01:37:48 [INFO] [üéØ SetFit] Intent: acknowledgment (confidence: 0.64)
01:37:48 [INFO] [‚ö° TEMPLATE] Bypassed LLM (confidence: 0.64)
01:37:48 [INFO] [‚ö° Response] Got it.

01:37:49 [INFO] ‚úÖ PROCESSING COMPLETE
01:37:49 [INFO] [VAD] üé§ UNLOCKED - Ready for new input
```
**Latency**: ~1 second (template bypass - no LLM needed!)

---

### Example 2: Identity Question (Hardcoded Response)
```
01:37:56 [INFO] [VAD] üé§ Speech START detected
01:37:58 [INFO] [VAD] üîá Speech END detected - LOCKING audio input

01:37:58 [INFO] üß† PROCESSING SPEECH SEGMENT
01:37:58 [INFO] [Audio Buffer] Collected 29696 samples (1.86s)
01:37:58 [INFO] [üìù Parakeet STT] Raw: "What is your purpose and who are you?"

Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 132.21it/s]

01:37:58 [INFO] [üéØ SetFit] Intent: project_idea (confidence: 0.28)
01:37:58 [INFO] [ü§ñ LLM Response] I'm AXIOM, a breakthrough voice assistant built by 
Shubham Dev under the Wired Brain Project at JUIT. I help with Drobotics Lab equipment, 
project ideas, and research guidance. What can I assist you with?

01:38:09 [INFO] ‚úÖ PROCESSING COMPLETE
```
**Latency**: ~11 seconds (LLM generation)

---

### Example 3: Equipment Query with Keyword Detection
```
01:38:31 [INFO] [VAD] üé§ Speech START detected
01:38:33 [INFO] [VAD] üîá Speech END detected - LOCKING audio input

01:38:33 [INFO] üß† PROCESSING SPEECH SEGMENT
01:38:33 [INFO] [Audio Buffer] Collected 32256 samples (2.02s)
01:38:34 [INFO] [üìù Parakeet STT] Raw: "What is the ordinal giga R."

Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 50.97it/s]

01:38:34 [INFO] [üéØ SetFit] Intent: equipment_query (confidence: 0.67)
01:38:34 [INFO] [üéØ KEYWORD MATCH] 'giga' ‚Üí Card 7 (Arduino GIGA R1 WiFi)
01:38:34 [INFO] [üéØ KEYWORD TRIGGER] Card 7: Arduino GIGA R1 WiFi

01:38:37 [INFO] HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
01:38:37 [INFO] [ü§ñ LLM Response] The GIGA R1 is an awesome microcontroller board! 
It's perfect for controlling motors, reading sensors, and processing data all on one 
powerful chip. You'll love its 8000+ I/O pins for creating complex robot systems. 
Want to know how it can help with your current project?

01:38:53 [INFO] ‚úÖ PROCESSING COMPLETE
```
**Features Demonstrated**:
- ‚úÖ Keyword detection: "giga" ‚Üí Arduino GIGA R1 WiFi
- ‚úÖ Carousel navigation triggered automatically
- ‚úÖ Context-aware LLM response

---

### Example 4: Multi-turn Conversation with 3D Model Change
```
01:39:13 [INFO] [VAD] üé§ Speech START detected
01:39:15 [INFO] [VAD] üîá Speech END detected - LOCKING audio input

01:39:15 [INFO] üß† PROCESSING SPEECH SEGMENT
01:39:15 [INFO] [Audio Buffer] Collected 24064 samples (1.50s)
01:39:15 [INFO] [üìù Parakeet STT] Raw: "What is robot dog?"

Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 47.89it/s]

01:39:15 [INFO] [üéØ SetFit] Intent: equipment_query (confidence: 0.68)
01:39:15 [INFO] [üéØ KEYWORD MATCH] 'robot' ‚Üí Card 13 (JetAuto Mecanum Robot)
01:39:15 [INFO] [üéØ KEYWORD TRIGGER] Card 13: Unknown
01:39:15 [INFO] [üé® 3D MODEL CHANGE] Topic: 'quadruped' ‚Üí Model: Unitree Go2 Robot Dog
01:39:15 [INFO] [üé® 3D Model] Loading: Unitree Go2 Robot Dog

01:39:17 [INFO] HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
01:39:17 [INFO] [ü§ñ LLM Response] Our robot dog, also known as Unitree Go2, is an 
amazing quadruped robot! It's built right here in the lab and features four legs for 
super agile movement. You can program it to walk, run, and even climb stairs. It's a 
seriously cool piece of tech. Want to see it in action? I can set up a demo for you.

01:39:35 [INFO] ‚úÖ PROCESSING COMPLETE
```
**Features Demonstrated**:
- ‚úÖ 3D model switching based on topic detection
- ‚úÖ Conversational, engaging responses
- ‚úÖ Contextual equipment information

---

### Example 5: Project Ideas with Semantic RAG
```
01:39:58 [INFO] [VAD] üé§ Speech START detected
01:40:00 [INFO] [VAD] üîá Speech END detected - LOCKING audio input

01:40:00 [INFO] üß† PROCESSING SPEECH SEGMENT
01:40:00 [INFO] [Audio Buffer] Collected 35840 samples (2.24s)
01:40:00 [INFO] [üìù Parakeet STT] Raw: "What projects can I build with it?"

Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 49.46it/s]

01:40:00 [INFO] [üéØ SetFit] Intent: project_idea (confidence: 0.69)
01:40:00 [INFO] [Semantic RAG] Found 3 projects for: 'What projects can I build with it?'
01:40:00 [INFO]   Top match: SLAM Robot (similarity: 0.34)

01:40:01 [INFO] HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
01:40:01 [INFO] [ü§ñ LLM Response] The possibilities are endless! You can create 
autonomous navigation systems, object tracking robots, and even manipulate objects 
using its gripper. It's perfect for learning about sensor integration and control 
algorithms. What kind of project excites you most? Shall we brainstorm some ideas?

01:40:17 [INFO] ‚úÖ PROCESSING COMPLETE
```
**Features Demonstrated**:
- ‚úÖ Semantic RAG retrieval (325 project database)
- ‚úÖ Context-aware follow-up questions
- ‚úÖ Conversational continuity

---

## Key Performance Metrics

| Metric | Value |
|--------|-------|
| **Template Bypass Latency** | ~1 second |
| **LLM Response Latency** | ~3-11 seconds |
| **STT Processing** | 50-130 it/s (batches) |
| **Intent Classification** | 9 intent labels |
| **Keyword Database** | 136 unique keywords, 27 products |
| **Semantic RAG** | 27 equipment, 325 projects, 10 authorities |
| **Template Responses** | 2,116 instant responses |

## Architecture Highlights

1. **Voice Activity Detection (VAD)**: Silero VAD with probability-based speech detection
2. **Speech-to-Text**: Parakeet TDT 0.6B (int8 quantized)
3. **Intent Classification**: SetFit with 9 intent categories
4. **Keyword Mapping**: 136 keywords ‚Üí 27 products with fuzzy matching
5. **3D Model System**: Dynamic GLB model loading based on topic detection
6. **Semantic RAG**: JSON + embeddings (all-MiniLM-L6-v2)
7. **Template Bypass**: 80% of queries skip LLM (2.8x faster)
8. **LLM**: Ollama (drobotics_test model)

---

**Note**: This is a real terminal session capture showing AXIOM's production performance on a GTX 1650 (4GB VRAM).
